\chapter{Kolmogorov Distance Bounds}
\label{C:stein-proof} In this chapter, we prove the core theoretical
results of this thesis: rate of convergence bounds on the Kolmogorov
distance between the randomization distribution of the $t$-statistic
and the standard normal distribution, using
Theorems~\ref{T:main} and \ref{T:better-rate} of Chapter~\ref{C:steins-method}.

\section{Motivation}
Motivated by concerns regarding normality
assumptions in the hypothesis being tested, Fisher
\cite{fisher1935design} proposed a nonparametric randomization test.
Also known as a permutation test, Fisher applied this novel test to
Charles Darwin's \emph{Zea mays} data and noted that the achieved
significance level was very similar to that observed in the parametric
test.  Indeed, Diaconis and Holmes \cite{diaconis1994gray} used
efficient Gray code based calculations to show that the randomization
distribution looked remarkably normal.  For more history on the
development of randomization procedures, see Zabell
\cite{zabell2008student} or David \cite{david2008beginnings}.
Diaconis and Lehmann \cite{diaconis2008comment} in their comment on
Zabell's paper further expanded on some properties of these
randomization tests.

Ludbrook and Dudley \cite{ludbrook1998permutation} have written about
the advantages of permutation tests, especially in biomedical
research, and outlined two models of statistical inference: the
so-called population model, formally introduced by Newman and Pearson
\cite{neyman1928use}, and Fisher's randomization model
\cite{fisher1935design}.  Add some more on these two models...

Under the randomization model and using the language of triangular
arrays, Lehmann \cite{lehmann1999elements} proved a weak convergence
result of the randomization distribution of the $t$-statistic to the
standard normal distribution, however, there is no known Berry-Esseen
type bound for this rate of convergence.

Introduced by Stein \cite{stein1986approximate}, the eponymous
technique provides a powerful means with which to handle dependencies
among collections of random variables, a common criticism of classical
Fourier analytic methods.  In addition, one can easily obtain bounds
on rates of convergence.  Bentkus and G{\"o}tze
\cite{bentkus1996berry} first obtained a Berry-Esseen bound for
Student's statistic in the independent but non-identically distributed
setting with additional work by Shao \cite{shao2005explicit}.

We use Stein's method of exchangeable pairs to prove a conservative
bound of $\mathcal{O}(n^{-1/4})$ on the rate of convergence of the randomization
$t$-distribution to the standard normal distribution.  With an
additional condition on the data, we are able to obtain a
$\mathcal{O}(n^{-1/2})$ rate.

\section{Set-up}
We observe two samples with equal sample size: $S_1 = \{u_i\}_{i=1}^N$
and $S_2 = \{u_i\}_{i=N+1}^{2N}$.  Since we consider the $t$-statistic
under different permutations, it will be convenient to re-write the
sample values relative to the null permutation $\pi_0$: $S_1 =
\{u_{\pi_0(i)}\}_{i=1}^N$ and $S_2 = \{u_{\pi_0(i)}\}_{i=N+1}^{2N}$,
where $\pi_0(i) = i$.  Under the randomization distribution, where
$\Pi$ is a uniformly chosen permutation, Student's two-sample
$t$-statistic is given by
\begin{align*}
T_{\Pi}(\{u_{\Pi(i)}\}_{i=1}^N, \{u_{\Pi(i)}\}_{i=N+1}^{2N})
&= \frac{\bar{u}_{1,\Pi} - \bar{u}_{2,\Pi}}{\sqrt{\frac{\frac{1}{N-1}
      \sum_{i=1}^N(u_{\Pi(i)} - \bar{u}_{1,\Pi})^2}{N} + \frac{\frac{1}{N-1}
      \sum_{i=N+1}^{2N}(u_{\Pi(i)} - \bar{u}_{2,\Pi})^2}{N}}} \\
&= \frac{1}{\sqrt{\frac{N}{N-1}}} \frac{\sum_{i=1}^N u_{\Pi(i)} -
  \sum_{i=N+1}^{2N}u_{\Pi(i)}}{\sqrt{\sum_{i=1}^N(u_{\Pi(i)} -
    \bar{u}_{1,\Pi})^2 + \sum_{i=N+1}^{2N}(u_{\Pi(i)} - \bar{u}_{2,\Pi})^2}} \\
&= \sqrt{\frac{N-1}{N}}\frac{q_\Pi}{d_\Pi},
\end{align*}
where
\begin{align*}
  q_\Pi &= \left (\sum_{i=1, i\neq I}^N u_{\Pi(i)} + u_{\Pi(I)} -
    \sum_{i=N+1, i\neq J}^{2N}u_{\Pi(i)} - u_{\Pi(J)}\right ) \\
  d_\Pi &= \sqrt{\sum_{i=1}^N(u_{\Pi(i)} - \bar{u}_{1,\Pi})^2 +
    \sum_{i=N+1}^{2N}(u_{\Pi(i)} - \bar{u}_{2,\Pi})^2} \\
  \bar{u}_{1,\Pi} &= \frac{1}{N} \sum_{i=1}^N u_{\Pi(i)} \text{ and }
  \bar{u}_{2,\Pi} = \frac{1}{N} \sum_{i=N+1}^{2N} u_{\Pi(i)}.
\end{align*}

In order to perform hypothesis testing, we compute the observed value
of $T_{\Pi=\pi_0}$ and compare that with the randomization
distribution of $T_{\Pi}$.  We shall create an exchangeable pair
$(T_{\Pi}, T_{\Pi}')$ by considering a uniformly random transposition
$(I, J)$.  WLOG, take $I \leq J$.  We apply this transposition to the
group labels.  Note that if $I, J \in \{1,\ldots,N\}$ or $I, J \in
\{N+1,\ldots,2N\}$ then $T_{\Pi}' = T_{\Pi}$, where $T_{\Pi}'$ is the
$t$-statistic under this random transposition.  That is, the
$t$-statistic is invariant to within-group transpositions: the only
changes occur when $1 \leq I \leq N$ and $N + 1 \leq J \leq 2N$.  With
this in mind, let's redefine our transposition to be uniformly at
random over the $N^2$ cases where $1 \leq I \leq N$ and $N + 1 \leq J
\leq 2N$. Thus,
\begin{align*}
  T'_{\Pi}(\{u_{\Pi(i)}\}_{i=1}^N, \{u_{\Pi(i)}\}_{i=N+1}^{2N})
  &= T_{\Pi \circ (I,J)}(\{u_{\Pi \circ (I,J)(i)}\}_{i=1}^N, \{u_{\Pi \circ (I,J)(i)}\}_{i=N+1}^{2N}) \\
  &= \sqrt{\frac{N-1}{N}}\frac{q'_{\Pi}}{d'_{\Pi}} \\
  q'_{\Pi} &= \left (\sum_{i=1, i\neq I}^N u_{\Pi(i)} + u_{\Pi(J)} -
    \sum_{i=N+1, i\neq J}^{2N}u_{\Pi(i)} - u_{\Pi(I)} \right ) \\
  &= q_{\Pi} - 2u_{\Pi(I)} + 2u_{\Pi(J)} \\
  d'_{\Pi} &= \sqrt{\sum_{i=1}^N(u_{\Pi(i)} - \bar{u}'_{1, \Pi})^{2} +
    \sum_{i=N+1}^{2N}(u_{\Pi(i)} - \bar{u}'_{2, \Pi})^{2}}.
\end{align*}

\section{Assumptions}
Recall that the $t$-statistic is invariant up to sign under affine
transformations, so we can mean-center and scale so that
$\sum_{i=1}^{2N} u_{i} = 0$ and $\sum_{i=1}^{2N} u_{i}^2 = 2N$.  The
transformation that achieves this centering and scaling is given by
\begin{equation}
  u_i \leftarrow \sqrt{\frac{2N}{\sum_{i=1}^{2N} (u_{i} - \bar{u})^2}}(u_{i}-\bar{u}),
\end{equation}
so we just assume that the $u_{i}$'s have already been transformed.
This can be seen as a very mild assumption: only $u_i = c$ for all $i$
cannot be scaled in this way.

We also assume that the pooled sample standard deviation is non-zero
for all permutations:
\begin{equation}
  \label{A:non-zero-std-dev}
  d_\Pi = \sqrt{\sum_{i=1}^N(u_{\Pi(i)} - \bar{u}_{1,\Pi})^2 +
    \sum_{i=N+1}^{2N}(u_{\Pi(i)} - \bar{u}_{2,\Pi})^2} > 0
\end{equation}
This estimate is zero if and only if there exists a grouping that is
constant in each group.  The condition also implies that the sample
mean for any group is strictly less than 1 in absolute value.  In
fact, this assumption subsumes the former.

The mean-centering assumption implies that
$\sum_{i=1}^{N} u_{\Pi(i)} = - \sum_{i=N+1}^{2N} u_{\Pi(i)}$
and hence that $\bar{u}_{1,\Pi} = -\bar{u}_{2,\Pi}$ for all $\Pi$.

Here we establish an equality with $d_{\Pi}$ that will prove easier to work with:
\begin{align*}
  d_\Pi^2 &=  \sum_{i=1}^N(u_{\Pi(i)} - \bar{u}_{1,\Pi})^2 +
  \sum_{i=N+1}^{2N}(u_{\Pi(i)} - \bar{u}_{2,\Pi})^2 \\
  &= \sum_{i=1}^{2N} u_{\Pi(i)}^2 - N \bar{u}_{1,\Pi}^2 - N \bar{u}_{2,\Pi}^2 \\
  &= 2N - N \bar{u}_{2,\Pi}^2 - N \bar{u}_{2,\Pi}^2 \\
  &= 2N(1 - \bar{u}_{2,\Pi}^2)
\end{align*}
Since $d_\Pi > 0$, it follows that $|\bar{u}_{2,\Pi}| < 1$.  Define
\begin{equation}
  \label{Assumption:B}
  B = \max_\Pi |\bar{u}_{2,\Pi}| < 1.
\end{equation}

\section{Preliminaries}
\label{S:stein-proof-preliminaries}
Here we collect useful bounds and other results.  We include them here rather than
in Appendix~\ref{A:auxiliary-app} because in Chapter~\ref{C:simulations} we compare
the theoretical bounds with simulated results.

In order to bound various moments of $\bar{u}_{2,\Pi}$ under the
permutation distribution, we use a result of Serfling's
\cite{serfling1974probability}:
\begin{proposition}
  Consider sampling without replacement from a finite list of values
  $u_1, \ldots, u_{2N}$.  Let $u_{\Delta} = \max_i u_{i} - \min_i
  u_{i}$.
  Then for $p > 0$,
  \begin{align}
    \E [\bar{u}_{2,\Pi}^p]
    &\leq \frac{\Gamma(p/2 + 1)}{2^{p/2 + 1}}
    \left [ \frac{N+1}{2N}u_{\Delta}^2 \right ]^{p/2}
    (2N)^{-p/2} \nonumber \\
    &\leq \frac{\Gamma(p/2 + 1)}{2^{p/2 + 1}}
    \left [ \frac{N+1}{4N}u_{\Delta}^2 \right ]^{p/2}
    N^{-p/2} \nonumber \\
    &:= f_{c_1}(p)N^{-p/2} \label{def:serfling}.
  \end{align}
\end{proposition}

By Assumption~\eqref{Assumption:B},
\begin{equation}
\label{def:dp}
  (d_{\Pi})^{-p} = \frac{1}{(2N(1-\bar{u}_{2,\Pi}^2))^{p/2}} \leq \frac{1}{(2N(1-B^2))^{p/2}} :=
  f_{c_2}(p) N^{-p/2}.
\end{equation}

The transposition $(I, J)$ also affects the denominator of $T_{\Pi}'$, and we need to quantify the
difference between the denominators of $T_{\Pi}$ and $T_{\Pi}'$.  Letting $\bar{u}_{2,\Pi}'^2$
denote the sample mean of the second group after the transposition,
\begin{align*}
  \bar{u}_{2,\Pi}'^2 &= \left ( \bar{u}_{2,\Pi}-\frac{1}{N}u_{\Pi(J)}+\frac{1}{N}u_{\Pi(I)} \right )^2 \\
  &= \bar{u}_{2,\Pi}^2 + 2 \bar{u}_{2,\Pi} \left ( -\frac{1}{N}u_{\Pi(J)} +
      \frac{1}{N}u_{\Pi(I)} \right ) + \frac{1}{N^2}(u_{\Pi(I)} - u_{\Pi(J)})^2
\end{align*}
We consider the difference
\begin{align*}
  h_{\Pi} &= d_{\Pi}^2 - d_{\Pi}'^2 \\
  &= 2N - 2N \bar{u}_{2,\Pi}^2 - 2N + 2N\bar{u}_{2,\Pi}'^2 \\
  &= 4\bar{u}_{2,\Pi}(u_{\Pi(I)} - u_{\Pi(J)}) + \frac{2}{N}(u_{\Pi(I)} - u_{\Pi(J)})^2
\end{align*}

Therefore, by the $c_r$-inequality,
\begin{align}
  \E[h_{\Pi}^p] &= \E \left | 4\bar{u}_{2,\Pi}(u_{\Pi(I)}-u_{\Pi(J)}) +
      \frac{2}{N}(u_{\Pi(I)}-u_{\Pi(J)})^2 \right |^p \nonumber \\
  &\leq 2^{p-1} \left ( \E |4\bar{u}_{2,\Pi}(u_{\Pi(I)}-u_{\Pi(J)})|^p
    + \E \left |\frac{2}{N}(u_{\Pi(I)}-u_{\Pi(J)})^2 \right |^p \right ) \nonumber \\
  &\leq 2^{p-1}\left [ (4u_{\Delta})^p \E \left | \bar{u}_{2,\Pi} \right |^p
    + \left ( \frac{2}{N}u_{\Delta}^2 \right )^p \right ] \nonumber \\
  &\leq 2^{p-1} (4u_{\Delta})^p f_{c_1}(p)N^{-p/2} +
  2^{p-1}(2u_{\Delta}^2)^pN^{-p} \nonumber \\
  &:= f_{c_3}(p)N^{-p/2} \label{def:hp}.
\end{align}

Now we establish a bound on the difference $d_{\Pi}-d_{\Pi}'$ via a
bound on the remainder of a zeroth order Taylor approximation.  Write
\begin{equation*}
  d_{\Pi}' = \sqrt{d_{\Pi}^2-h_{\Pi}} = f(h_{\Pi}) = f(0) + R_0(h_{\Pi}) = d_{\Pi} + R_0(h_{\Pi})
\end{equation*}

By Taylor's theorem, the remainder of the zeroth-order expansion takes the form
\begin{equation*}
  R_0(h_{\Pi}) = \frac{f'(\xi_L)}{1}h_{\Pi} = \frac{-h_{\Pi}}{2\sqrt{d_{\Pi}^2-\xi_L}}, \quad
  \text{where } \xi_L \in [0, h_{\Pi}].
\end{equation*}

We are approximating $d_{\Pi}'$ by a constant and bounding the error via a function of the first
derivative.  This is a sufficient approximation because the squared difference $h_{\Pi}$ is not so
big relative to the flattening out of the square root function.
Now
\begin{equation*}
  |d_{\Pi}-d_{\Pi}'| \leq |R_0(h_{\Pi})| \leq \frac{|h_{\Pi}|}{2\sqrt{d_{\Pi}^2-\xi_L}} \leq
  \frac{|h_{\Pi}|}{2\sqrt{d_{\Pi}^2-\max(0, h_{\Pi})}}
\end{equation*}
Recall that $h_{\Pi} = d_{\Pi}^2 - d_{\Pi}'^2$, so
\begin{equation*}
  d_{\Pi}^2-\max(0, d_{\Pi}^2-d_{\Pi}'^2) =
  \begin{cases}
    d_{\Pi}^2 & \text{if } d_{\Pi}^2-d_{\Pi}'^2 \leq 0 \\
    d_{\Pi}'^2 & \text{if } d_{\Pi}^2-d_{\Pi}'^2 > 0
  \end{cases}
\end{equation*}
Therefore,
\begin{equation*}
  |d_{\Pi}-d_{\Pi}'| \leq \frac{|h_{\Pi}|}{2\min(d_{\Pi}, d_{\Pi}')} \leq \max \left (
    \frac{|h_{\Pi}|}{2d_{\Pi}}, \frac{|h_{\Pi}|}{2d_{\Pi}'} \right ) \leq
  \frac{|h_{\Pi}|}{2d_{\Pi}} +  \frac{|h_{\Pi}|}{2d_{\Pi}'}.
\end{equation*}

The important thing to do is to isolate $|h_{\Pi}|$, which is small in
expectation, but not absolutely.  By the $c_r$-inequality,
\begin{align}
  \E |d_{\Pi}-d_{\Pi}'|^p
  &\leq 2^{p-1} \left ( \E \left | \frac{h_{\Pi}}{2d_{\Pi}} \right |^p + \E \left |
      \frac{h_{\Pi}}{2d_{\Pi}'} \right |^p \right ) \nonumber \\
  &\leq 2^{-1} \left ( \sqrt{\E[h_{\Pi}^{2p}]\E[d_{\Pi}^{-2p}]} +
  \sqrt{\E[h_{\Pi}^{2p}]\E[d_{\Pi}'^{-2p}]} \right ) \nonumber \\
  &\leq \sqrt{f_{c_3}(2p)N^{-2p/2} f_{c_2}(2p) N^{-2p/2}} \quad \text{ by } \eqref{def:hp}
  \text{ and } \eqref{def:dp} \nonumber \\
  &:= f_{c_4}(p) N^{-p} \label{def:ddiffp}.
\end{align}

With
\begin{equation}
  \label{eq:qpi}
  q_{\Pi} = N\bar{u}_{1,\Pi} - N\bar{u}_{2,\Pi} = -2N\bar{u}_{2,\Pi},
\end{equation}
\eqref{def:serfling}, and noting that $q_{\Pi}$ and $q_{\Pi}'$ are exchangeable,
\begin{equation}
\label{def:qp}
  \E[q_{\Pi}'^p] = \E[q_{\Pi}^p] = \E[(-2N\bar{u}_{2,\Pi})^p]
  \leq 2^pN^p f_{c_1}(p)N^{-p/2} := f_{c_5}(p).
\end{equation}

\begin{align}
  \E \left [ \left ( \frac{q_{\Pi}'}{d_{\Pi}d_{\Pi}'} \right )^p \right ]
  &\leq \sqrt{\E |q_{\Pi}'|^{2p} \E |d_{\Pi}d_{\Pi}'|^{-2p}} \nonumber \\
  &\leq \sqrt{\E |q_{\Pi}|^{2p} \sqrt{\E |d_{\Pi}|^{-4p} \E |d_{\Pi}'|^{-4p}}} \nonumber \\
  &= \sqrt{\E |q_{\Pi}|^{2p} \E |d_{\Pi}|^{-4p}} \nonumber \\
  &\leq \sqrt{f_{c_5}(2p) N^{2p/2} f_{c_2}(4p) N^{-4p/2}} \quad \text{ from
  } \eqref{def:qp} \text{ and } \eqref{def:dp} \nonumber \\
  &:= f_{c_6}(p) N^{-p/2} \label{def:qpddp}.
\end{align}

\section{Proof}
We proceed to verify the conditions of Theorems~\ref{T:main} and \ref{T:better-rate}.
$T_{\Pi}$ and $T_{\Pi}'$ are exchangeable by construction:
\begin{align*}
  P(\Pi = \pi, \Pi' = \pi') &= P(\Pi' = \pi' | \Pi = \pi)P(\Pi = \pi) \\
  &= \frac{1}{N^2}\mathbbm{1}_{\{\pi'=\pi \circ (i,j), 1\leq i \leq N, N+1 \leq j \leq 2N\}} P(\Pi =
  \pi') \\
  &=\frac{1}{N^2}\mathbbm{1}_{\{\pi=\pi' \circ (i,j), 1\leq i \leq N, N+1 \leq j \leq 2N\}} P(\Pi =
  \pi') \\
  &= P(\Pi' = \pi | \Pi = \pi')P(\Pi = \pi') \\
  &= P(\Pi = \pi', \Pi' = \pi)
\end{align*}

Since $(\Pi, \Pi')$ are exchangeable, $(T_{\Pi}, T_{\Pi}') = (T(\Pi), T(\Pi'))$ are exchangeable as
well.  $T_{\Pi}$, and thus $T_{\Pi}'$ by exchangeability, have mean zero by symmetry.  Let $\pi^*$ identify
the permutation that reverses the order of the indices after applying the original permutation
$\pi$.  That is, $\pi^* = (2N, \ldots, 1) \circ \pi$.  Since indices $1$ to $N$ correspond to the
first group and $N+1$ to $2N$ to the second, $\pi^*$ reverses the groups after $\pi$, so $T_{\pi^*} =
-T_{\pi}$.
\begin{align*}
  P(T_{\Pi} = t) &= \sum_{\pi : T_{\pi} = t} P(\Pi = \pi) \\
  &= \sum_{\pi : T_{\pi} = t} P(\Pi = \pi^*) \quad \text{by exchangeability} \\
  &= \sum_{\pi^* : T_{\pi^*} = -t} P(\Pi = \pi^*) \quad \text{since } T_{\pi^*} = -T_{\pi} \text{
    and } \pi \mapsto \pi^* \text{ is bijective} \\
  &= P(T_{\Pi} = -t)
\end{align*}

To show the approximate regression condition, the difference of our exchangeable pair is given by
\begin{align}
  T_{\Pi}' - T_{\Pi}
  &= \sqrt{\frac{N-1}{N}}\left (\frac{q_{\Pi}'}{d_{\Pi}'}-\frac{q_{\Pi}}{d_{\Pi}}\right )
  \nonumber \\
  &= \sqrt{\frac{N-1}{N}}\frac{1}{d_{\Pi}}\left (q_{\Pi}' - q_{\Pi} +
    q_{\Pi}' \frac{(d_{\Pi}-d_{\Pi}')}{d_{\Pi}'}\right ) \nonumber \\
  &= \sqrt{\frac{N-1}{N}}\frac{1}{d_{\Pi}}\left
    (2u_{\Pi(J)} - 2u_{\Pi(I)} + q_{\Pi}' \frac{(d_{\Pi}-d_{\Pi}')}{d_{\Pi}'}\right ). \label{def:ttpcubed}
\end{align}
Note that
\begin{align*}
  \sqrt{\frac{N-1}{N}} \E \left [ \frac{1}{d_{\Pi}} (2u_{\Pi(J)} - 2u_{\Pi(I)}) \middle | \Pi = \pi \right ]
  &= \sqrt{\frac{N-1}{N}} \frac{2}{d_{\Pi}} \frac{1}{N^2} \sum_{I=1}^N \sum_{I=N+1}^{2N} (u_{\Pi(J)}-u_{\Pi(I)}) \\
  &= -\frac{2}{N} T_{\Pi}.
\end{align*}
Therefore,
\begin{equation*}
  \sqrt{\frac{N-1}{N}} \E \left [ \frac{1}{d_{\Pi}} (2u_{\Pi(J)} - 2u_{\Pi(I)}) \middle | \Pi = \pi \right ]
  = \sqrt{\frac{N-1}{N}} \E \left [ \frac{1}{d_{\Pi}} (2u_{\Pi(J)} - 2u_{\Pi(I)}) \middle | T_{\Pi} \right ]
\end{equation*}
and
\begin{equation*}
  \lambda = \frac{2}{N}.
\end{equation*}

\begin{align*}
  \E[T_{\Pi}'-T_{\Pi}|T_{\Pi}]
  &= - \lambda T_{\Pi} + \sqrt{\frac{N-1}{N}}
  \E\left [\frac{q_{\Pi}'}{d_{\Pi}} \frac{(d_{\Pi}-d_{\Pi}')}{d_{\Pi}'}\middle |T_{\Pi} \right ] \\
  &= - \lambda \left ( T_{\Pi} - \left ( \frac{N}{2} \right )
    \sqrt{\frac{N-1}{N}}
    \E\left [\frac{q_{\Pi}'}{d_{\Pi}} \frac{(d_{\Pi}-d_{\Pi}')}{d_{\Pi}'}\middle |T_{\Pi} \right ] \right )
\end{align*}
so
\begin{equation}
  \label{def:Rdef}
  R_{\Pi} = \left (\frac{N}{2}\right )\sqrt{\frac{N-1}{N}}\frac{1}{d_{\Pi}}\E
  \left [q_{\Pi}'\frac{(d_{\Pi}-d_{\Pi}')}{d_{\Pi}'} \middle | T_{\Pi} \right ].
\end{equation}

For convenience, we restate Theorem~\ref{T:main} of
Chapter~\ref{C:steins-method}, taking our random variables $W$ to be
the randomization $t$-statistic $T_{\Pi}$ and $W'$ to be its coupled
counterpart $T_{\Pi}'$:
\begin{thma}
  If $T_{\Pi}$, $T_{\Pi}'$ are mean 0 exchangeable random variables with variance $\E T_{\Pi}^2$
  satisfying
  \begin{equation*}
    \E[T_{\Pi}'-T_{\Pi}|T_{\Pi}] = -\lambda(T_{\Pi}-R_{\Pi})
  \end{equation*}
  for some $\lambda \in (0,1)$ and some random variable $R_{\Pi}$, then
  \begin{equation*}
    \begin{split}
      \sup_{t \in \mathbb{R}} |P(T_{\Pi} \leq t) - \Phi(t)|
      &\leq (2\pi)^{-1/4} \sqrt{\frac{\E |T_{\Pi}'-T_{\Pi}|^3}{\lambda}}
      + \frac{1}{2\lambda} \sqrt{\var (\E [(T_{\Pi}'-T_{\Pi})^2|T_{\Pi}])} \\
      &\quad + |\E T_{\Pi}^2 - 1| + \E |T_{\Pi}R_{\Pi}| + \E |R_{\Pi}|
    \end{split}
  \end{equation*}
\end{thma}

With the preliminaries in place, we proceed to provide bounds on each
term in Theorem~\ref{T:main}, the proofs of which we defer to Appendix~\ref{A:stein-proof-app}.

\begin{proposition}
  \label{P:P3}
  $(2\pi)^{-1/4}\sqrt{\frac{\E|T_{\Pi}'-T_{\Pi}|^3}{\lambda}}
  < (2\pi)^{-1/4} c_9 N^{-1/4}$.
\end{proposition}

\begin{proposition}
  \label{P:P2}
  $\frac{1}{2\lambda} \sqrt{\var (\E [(T_{\Pi}'-T_{\Pi})^2|T_{\Pi}])} \leq
  N^{-1} c_3\sqrt{20 + 16\frac{\sum_{i=1}^{2N} u_{i}^4}{N^2}}$
\end{proposition}

\begin{proposition}
  \label{P:P1}
  $|\E T_{\Pi}^2 -1| \leq c_2 N^{-1}$
\end{proposition}

\begin{proposition}
  \label{P:P5}
  $\E|T_{\Pi}R|
  \leq \frac{1}{2}(f_{c_6}(4)f_{c_4}(4))^{1/4} \sqrt{2+2c_1} N^{-1/2}$.
\end{proposition}

\begin{proposition}
  \label{P:P4}
  $\E|R|
  \leq \frac{1}{2}\sqrt{f_{c_6}(2)f_{c_4}(2)} N^{-1/2}$.
\end{proposition}

The bound in Proposition~\ref{P:P3} is suboptimal, as it will only allow us to
obtain a rate of $\mathcal{O}(n^{-1/4})$.  In Section~\ref{S:better-rate}, we
introduce an additional condition to improve upon this rate.

Collecting the results of Propositions \ref{P:P1}, \ref{P:P2}, \ref{P:P3},
\ref{P:P4}, and \ref{P:P5}, we have
\begin{equation*}
  \begin{split}
    \sup_{t \in \mathbb{R}} |P(T_{\Pi} \leq t) - \Phi(t)|
    &\leq (2\pi)^{-1/4} \sqrt{\frac{\E |T_{\Pi}'-T_{\Pi}|^3}{\lambda}}
    + \frac{1}{2\lambda} \sqrt{\var (\E [(T_{\Pi}'-T_{\Pi})^2|T_{\Pi}])} \\
    &\quad + |\E T_{\Pi}^2 - 1| + \E |T_{\Pi}R_{\Pi}| + \E |R_{\Pi}| \\
    &\leq  (2\pi)^{-1/4} c_9 N^{-1/4} +
    N^{-1} c_3\sqrt{20 + 16\frac{\sum_{i=1}^{2N} u_{i}^4}{N^2}} + c_2 N^{-1} \\
    &\quad + \frac{1}{2}(f_{c_6}(4)f_{c_4}(4))^{1/4} \sqrt{2+2c_1} N^{-1/2} +
    \frac{1}{2}\sqrt{f_{c_6}(2)f_{c_4}(2)} N^{-1/2}
  \end{split}
\end{equation*}

Note that since $\norm{{\bf x}}_4 \leq \norm{{\bf x}}_2$,
\begin{equation*}
  \sum_{i=1}^{2N} u_{i}^4 \leq \left ( \sum_{i=1}^{2N} u_{i}^2 \right )^{4/2} = (2N)^2 = 4N^2.
\end{equation*}

This result is similar to the HCCLT.  Given fixed data, we can obtain an explicit
upper bound on the Kolmogorov distance between the randomization distribution of
our statistic of interest and the standard normal distribution.

\section{Better Rate}
\label{S:better-rate}
Here, we use Theorem~\ref{T:better-rate} to establish a rate of
$\mathcal{O}(n^{-1/2})$ with the condition that $|T_{\Pi}-T'_{\Pi}| \leq \delta$
is $\mathcal{O}(n^{-1/2})$.

From Proposition~\ref{P:P1}, $\E T_{\Pi}^2 \leq c_2 N^{-1} + 1$, and
from Proposition~\ref{P:P4}, $\E|R| \leq
\frac{1}{2}\sqrt{f_{c_6}(2)f_{c_4}(2)} N^{-1/2}$.
If $\delta < c_{10}N^{-1/2}$ for $N$ sufficiently large, applying
Theorem~\ref{T:better-rate}, we see
\begin{equation*}
  \begin{split}
    \sup_{t \in \mathbb{R}} |P(T_{\Pi} \leq t) - \Phi(t)|
    &\leq \frac{.41 \delta^3}{\lambda} + 3 \delta \left ( \sqrt{\E T_{\Pi}^2} + \E |R| \right )
    + \frac{1}{2\lambda} \sqrt{\var (\E [(T_{\Pi}'-T_{\Pi})^2|T_{\Pi}])} \\
    &\quad + |\E T_{\Pi}^2 - 1| + \E |T_{\Pi} R| + \E |R| \\
    &\leq .205 c_{10} N^{-1/2} + 3c_{10} N^{-1/2} \left (
      c_2 N^{-1} + 1 + \frac{1}{2}\sqrt{f_{c_6}(2)f_{c_4}(2)} N^{-1/2}
      \right ) \\
    &\quad + N^{-1} c_3\sqrt{20 + 16\frac{\sum_{i=1}^{2N} u_{i}^4}{N^2}} + c_2 N^{-1} \\
    &\quad + \frac{1}{2}(f_{c_6}(4)f_{c_4}(4))^{1/4} \sqrt{2+2c_1} N^{-1/2} +
    \frac{1}{2}\sqrt{f_{c_6}(2)f_{c_4}(2)} N^{-1/2}.
  \end{split}
\end{equation*}

Again, this result is conditional on the data.  We can consider a sequence
of vectors $\{u_i^{(2N)}\}$, where each $u_i^{(j)}$ is drawn from some distribution $p$.
As long as all data-dependent functions of the bound are ``well-behaved,'' we shall
have the desired rates of convergence, such as in \cite{bolthausen1984estimate}.

To determine whether $\delta = |T_{\Pi}-T'_{\Pi}|$ is
$\mathcal{O}(n^{-1/2})$ for reasonable classes of data $\{u_i\}$, recall that
\begin{align*}
T_{\Pi}(\{u_{\Pi(i)}\}_{i=1}^N, \{u_{\Pi(i)}\}_{i=N+1}^{2N})
&= \frac{\bar{u}_{1,\Pi} - \bar{u}_{2,\Pi}}{\sqrt{\frac{\frac{1}{N-1}
      \sum_{i=1}^N(u_{\Pi(i)} - \bar{u}_{1,\Pi})^2}{N} + \frac{\frac{1}{N-1}
      \sum_{i=N+1}^{2N}(u_{\Pi(i)} - \bar{u}_{2,\Pi})^2}{N}}}. \\
\end{align*}

We need to set $\delta = \max_{\pi, i, j} |T_{\pi} - T_{\pi \circ (i, j)}|$
so that the bound is tight.  This appears to be a daunting
optimization problem.  There are $(2N)!$ permutations and $N^2$
possible transpositions $(i, j)$ for each permutation.  Well, because the
$t$-statistic is invariant to permutations within groups, there are
$\binom{2N}{N}$ (really, $\binom{2N}{N} / 2$ because of symmetry)
permutations to consider.

We have to solve the maximization problem jointly over $T$ and $T'$.  We can
attempt to first maximize over $T$ and then $T'$.  Note that these sequential
approaches do not work for general optimization problems.

If we sort the data in ascending order such that the two groups are
$\{u_{(i)}\}_{i=1}^{N}$ and $\{u_{(i)}\}_{i=N+1}^{2N}$, then it seems like
we will have maximized $|T|$.  The absolute difference between the sample
means of the two groups is maximized, while the pooled sample standard
deviation is minimized (is this true? source?).

The transposition that should then maximize $|T - T'|$ is $(1, 2N)$ since it
swaps the most different points, decreasing the difference in sample means and
increasing the pooled sample standard deviation.

Let $\pi^*$ be the permutation that sorts the data in ascending order
such that $u_{\pi^*(i)} = u_{(i)}$, where $u_{(i)}$ are the order statistics
of $\{u_i\}$.  Let $i^* = 1$ and $j^* = 2N$.

\begin{conjecture}
  $\delta = \max_{\pi, i, j} |T_{\pi} - T_{\pi \circ (i, j)}|$ is maximized at
  $\pi = \pi^*$, $i = i^*$, and $j = j^*$.
\end{conjecture}

This conjecture has held true under many simulations.  We can show that when $u_i = i$,
\begin{equation*}
  \lim_{n \to \infty} \delta \sqrt{n} = 16 \sqrt{6}.
\end{equation*}