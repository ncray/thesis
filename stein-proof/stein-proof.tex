\chapter{Main Proof}
\label{C:stein-proof}
In this chapter, we prove the core theoretical result of this thesis, a rate of convergence bound for
the randomization distribution, using the theorem of chapter~\ref{C:steins-method}.

\section{Motivation}
Motivated by concerns regarding normality assumptions in the hypothesis being tested, Fisher
\cite{fisher1935design} proposed a nonparametric randomization test.  Also known as a permutation
test, Fisher applied this novel test to Charles Darwin's \emph{Zea mays} data and noted that the
achieved significance level was very similar to that observed in the parametric test.  Indeed,
Diaconis and Holmes \cite{diaconis1994gray} used efficient Gray code based calculations to show that
the randomization distribution looked remarkably normal.  For more history on the development of
randomization procedures, see Zabell \cite{zabell2008student} or David \cite{david2008beginnings}.
Diaconis and Lehmann \cite{diaconis2008comment} in their comment on Zabell's paper further expanded
on some properties of these randomization tests.

Ludbrook and Dudley \cite{ludbrook1998permutation} have written about the advantages of permutation
tests, especially in biomedical research, and outlined two models of statistical inference: the
so-called population model, formally introduced by Newman and Pearson \cite{neyman1928use}, and
Fisher's randomization model \cite{fisher1935design}.  Add some more on these two models...

Under the randomization model and using the language of triangular arrays, Lehmann
\cite{lehmann1999elements} proved a weak convergence result of the randomization distribution of the
$t$-statistic to the standard normal distribution, however, there is no known Berry-Esseen type
bound for this rate of convergence.

Introduced by Stein \cite{stein1986approximate} (cite earlier one?), the eponymous technique
provides a powerful means with which to handle dependencies among collections of random variables, a
common criticism of classical Fourier analytic methods.  In addition, one can easily obtain bounds
on rates of convergence.  Bentkus and G{\"o}tze \cite{bentkus1996berry} first obtained a
Berry-Esseen bound for Student's statistic in the independent but non-identically distributed
setting with additional work by Shao \cite{shao2005explicit}.

We use Stein's method of exchangeable pairs to prove a conservative bound of $O(N^{-1/4})$ on the
rate of convergence of the randomization $t$ distribution to the standard normal distribution.

\section{Set-up}
We observe two samples with equal sample size: $\{u_i\}_{i=1}^N$ and $\{u_i\}_{i=N+1}^{2N}$.
Student's two-sample $t$-statistic is given by
\begin{align*}
T(\{u_i\}_{i=1}^N, \{u_i\}_{i=N+1}^{2N}) 
&= \frac{\bar{u}_1 - \bar{u}_2}{\sqrt{\frac{\frac{1}{N-1}
      \sum_{i=1}^N(u_i - \bar{u}_1)^2}{N} + \frac{\frac{1}{N-1}
      \sum_{i=N+1}^{2N}(u_i - \bar{u}_2)^2}{N}}} \\
&= \frac{1}{\sqrt{\frac{N}{N-1}}} \frac{\sum_{i=1}^N u_i -
  \sum_{i=N+1}^{2N}u_i}{\sqrt{\sum_{i=1}^N(u_i - 
    \bar{u}_1)^2 + \sum_{i=N+1}^{2N}(u_i - \bar{u}_2)^2}} \\
&= \sqrt{\frac{N-1}{N}}\frac{q}{d},
\end{align*}
where
\begin{align*}
  q &= \left (\sum_{i=1, i\neq I}^N u_i + u_I -
    \sum_{i=N+1, i\neq J}^{2N}u_i - u_J\right ) \\
  d &= \sqrt{\sum_{i=1}^N(u_i - \bar{u}_1)^2 +
    \sum_{i=N+1}^{2N}(u_i - \bar{u}_2)^2}.
\end{align*}

In order to perform hypothesis testing, we would like to know the randomization distribution of $T$.
We shall create an exchangeable pair $(T, T')$ by considering a uniformly random transposition $(I,
J)$.  WLOG, take $I \leq J$.  We apply this transposition to the group labels.  Note that if $I, J
\in \{1,\ldots,N\}$ or $I, J \in \{N+1,\ldots,2N\}$ then $T' = T$, where $T'$ is the $t$-statistic
under this random transposition.  That is, the $t$-statistic is invariant to within-group
transpositions: the only changes occur when $1 \leq I \leq N$ and $N + 1 \leq J \leq 2N$.
With this in mind, let's redefine our transposition to be uniformly at random over the $N^2$ cases
where $1 \leq I \leq N$ and $N + 1 \leq J \leq 2N$. Thus,
\begin{align*}
  T'(\{u_i\}_{i=1}^N, \{u_i\}_{i=N+1}^{2N}) 
  &= \sqrt{\frac{N-1}{N}}\frac{q'}{d'} \\
  q' &= \left (\sum_{i=1, i\neq I}^N u_i + u_J -
    \sum_{i=N+1, i\neq J}^{2N}u_i - u_I \right ) \\
  &= q - 2u_I + 2u_J \\
  d' &= \sqrt{\sum_{i=1}^N(u_i - \bar{u}'_1)^{2} +
    \sum_{i=N+1}^{2N}(u_i - \bar{u}'_2)^{2}}.  
\end{align*}

\section{Assumptions}
Recall that the $t$-statistic is invariant up to sign under linear transformations, so we can
mean-center and scale so that $\sum_{i=1}^{2N} u_i = 0$ and $\sum_{i=1}^{2N} u_i^2 = 2N$.  The
proper transformation is 
\begin{equation}
  z_i = \sqrt{\frac{2N}{\sum (u_i - \bar{u})^2}}(u_i-\bar{u}), 
\end{equation}
so we just consider the $u_i$'s as having been transformed.  This can be seen as a very mild
assumption of disallowing the case where all our data are constant.  

We also assume that
\begin{equation}
  B = \max_{\pi} \bar{u}_2^2 < 1.
\end{equation}
This rejects situations like $(1, 1, \ldots, -1, -1)$.

\section{Preliminaries}
Here we collect useful bounds and other results.

In order to bound various moments of $\bar{u}_2$ under the permutation
distribution, we use a result of Serfling's
\cite{serfling1974probability}:
\begin{theorem}
  Consider sampling without replacement from a finite list of values
  $u_1, \ldots, u_{2N}$.  Let $a = \min_i u_i$ and $b = \max_i u_i$.
  Then for $p > 0$,
  \begin{align}
    \E [\bar{u}_2^p] 
    &\leq \frac{\Gamma(p/2 + 1)}{2^{p/2 + 1}}
    \left [ \frac{N+1}{2N}(b-a)^2 \right ]^{p/2}
    (2N)^{-p/2} \nonumber \\
    &\leq \frac{\Gamma(p/2 + 1)}{2^{p/2 + 1}}
    \left [ \frac{N+1}{4N}(b-a)^2 \right ]^{p/2}
    (N)^{-p/2} \nonumber \\
    &\leq \frac{\Gamma(p/2 + 1)}{2^{p/2 + 1}}
    \left [ \frac{1}{2}(b-a)^2 \right ]^{p/2}
    N^{-p/2} \nonumber \\
    &:= f_{c_1}(p)N^{-p/2} \label{def:serfling}.
  \end{align}
\end{theorem}

By assumption,
\begin{align}
  d^{-p} &= \frac{1}{(2N(1-\bar{u}_2^2))^{p/2}} \nonumber \\
  &\leq \frac{1}{(2N(1-B^2))^{p/2}} \nonumber \\
  &= \frac{1}{(2(1-B^2))^{p/2}}N^{-p/2} \nonumber \\
  &:= f_{c_2}(p) N^{-p/2} \label{def:dp}.
\end{align}

The transposition $(I, J)$ also affects the denominator of $T'$, and we need to quantify the
difference between the denominators of $T$ and $T'$.  
\begin{align*}
    d^2 &= \sum_{i=1}^N (u_i - \bar{u}_1)^2 + \sum_{i=N+1}^{2N} (u_i -
    \bar{u}_2)^2 = \sum_{i=1}^{2N} u_i^2 - N \bar{u}_1^2 - N
    \bar{u}_2^2 \\
    d'^2 &= \sum_{i=1}^{2N} u_i^2 - N \bar{u}_1'^2 - N \bar{u}_2'^2,  
\end{align*}
where
\begin{equation*}
  \label{eq:6}
  \bar{u}_1' = \bar{u}_1 - \frac{1}{N}u_I + \frac{1}{N}u_J \text{ and }
  \bar{u}_2' = \bar{u}_2 - \frac{1}{N}u_J + \frac{1}{N}u_I.
\end{equation*}
So, 
\begin{equation*}
  \label{eq:7}
  \bar{u}_1'^2 = \bar{u}_1^2 + \frac{2\bar{u}_1}{N}(u_J-u_I) +
  \frac{1}{N^2}(u_J-u_I)^2
\end{equation*}
and
\begin{equation*}
  \label{eq:8}
  \bar{u}_2'^2 = \bar{u}_2^2 + \frac{2\bar{u}_2}{N}(u_I-u_J) +
  \frac{1}{N^2}(u_I-u_J)^2.
\end{equation*}
Since $\sum u_i = 0$, $\bar{u}_1 = -\bar{u}_2$, so
\begin{align*}
  h &= d^2-d'^2 \\
  &= -N \bar{u}_1^2 -N \bar{u}_2^2 + N\bar{u}_1^{'2} + N\bar{u}_2^{'2} \\
  &= 2\bar{u}_1(u_J-u_I) + 2\bar{u}_2(u_I-u_J)+\frac{2}{N}(u_I-u_J)^2 \\
  &= 4\bar{u}_2(u_I-u_J) + \frac{2}{N}(u_I-u_J)^2
\end{align*}
Therefore,
\begin{align}
  \E[h^p] &= \E \left [ \left | 4\bar{u}_2(u_I-u_J) +
      \frac{2}{N}(u_I-u_J)^2 \right |^p \right ] \nonumber \\
  &\leq 2^{p-1} \left ( \E[|4\bar{u}_2(u_I-u_J)|^p] 
    + \E \left [ \left |\frac{2}{N}(u_I-u_J)^2 \right |^p \right ]
  \right ) \nonumber \\
  &\leq 2^{p-1}\left [ (4(b-a))^p \E \left | \bar{u}_2 \right |^p
    + \left ( \frac{2}{N}(b-a)^2 \right )^p \right ] \nonumber \\
  &\leq 2^{p-1} (4(b-a))^p f_{c_1}(p)N^{-p/2} +
  2^{p-1}(2(b-a)^2)^pN^{-p/2}N^{-p/2} \nonumber \\
  &\leq (2^{p-1} (4(b-a))^p f_{c_1}(p)N^{-p/2} +
  2^{p-1}(2(b-a)^2)^p)N^{-p/2} \nonumber \\
  &:= f_{c_3}(p)N^{-p/2} \label{def:hp}.
\end{align}

Now we consider the difference $d-d'$.  For a given $d$ (which grows
linearly), consider $d'$ as a function of the difference:
\begin{equation*}
  d' = \sqrt{d^2-h} = f(h) = f(0) + f'(0) h + \ldots = d -
  \frac{h}{2d} + \ldots
\end{equation*}

The derivative is
\begin{equation*}
  f'(h) = \frac{d}{\sqrt{d^2-h}}
\end{equation*}

By Taylor's theorem, the remainder of the zeroth-order expansion takes
the form 
\begin{equation*}
  R_0(h) = \frac{f'(\xi_L)}{1}h = \frac{-h}{2\sqrt{d^2-\xi_L}}, \quad
  \text{where } \xi_L \in [0, h].
\end{equation*}

Here, we are approximating $d'$ by a constant and bounding the error
by using the first derivative, but it's okay because the square root
function flattens out and the difference inside the square root is
probabilistically small.

Now
\begin{equation*}
  |d-d'| \leq \frac{|h|}{2\sqrt{d^2-\xi_L}} \leq
  \frac{|h|}{2\sqrt{d^2-\max(0, h)}}
\end{equation*}

Recall that $h = d^2 - d'^2$, so 
\[
d^2-\max(0, d^2-d'^2) = 
\begin{cases}
  d^2 & \text{if } d^2-d'^2 \leq 0 \\
  d'^2 & \text{if } d^2-d'^2 > 0
\end{cases}
\]

Therefore, 
\begin{equation*}
  |d-d'| \leq \frac{|h|}{2\min(d, d')} \leq \max \left (
    \frac{|h|}{2d}, \frac{|h|}{2d'} \right ) \leq 
  \frac{|h|}{2d} +  \frac{|h|}{2d'}.
\end{equation*}

The important thing to do is to isolate $|h|$, which is small in
expectation, but not absolutely.
\begin{align}
  \E |d-d'|^p 
  &\leq 2^{p-1} \left ( \E \left | \frac{h}{2d} \right |^p + \E \left |
      \frac{h}{2d'} \right |^p \right ) \nonumber \\
  &\leq 2^{-1} \left ( \E \left | \frac{h}{d} \right |^p + \E \left |
      \frac{h}{d'} \right |^p \right ) \nonumber \\
  &\leq 2^{-1} ( \sqrt{\E[h^{2p}]\E[d^{-2p}]} +
  \sqrt{\E[h^{2p}]\E[d'^{-2p}]} ) \nonumber \\
  &\leq \sqrt{\E[h^{2p}]\E[d^{-2p}]} \nonumber \\
  &\leq \sqrt{f_{c_3}(2p)N^{-2p/2} f_{c_2}(2p) N^{-2p/2}} \nonumber \\
  &\leq \sqrt{f_{c_3}(2p) f_{c_2}(2p)} N^{-p} \nonumber \\
  &:= f_{c_4}(p) N^{-p} \label{def:ddiffp}.
\end{align}

With $q = N\bar{u}_1 - N\bar{u_2} = -2N\bar{u_2}$, and noting that $q$ and $q'$ are
exchangeable,
\begin{align}
  \E[q'^p] 
  &= \E[q^p] \nonumber \\
  &= \E[(-2N\bar{u}_2)^p] \nonumber \\
  &= (-2N)^p \E[\bar{u}_2^p] \nonumber \\
  &\leq 2^pN^p f_{c_1}(p)N^{-p/2} \text{ from } (\ref{def:serfling})
  \nonumber \\
  &= 2^p f_{c_1}(p)N^{p/2} \nonumber \\
  &:= f_{c_5}(p) N^{p/2} \label{def:qp}.
\end{align}

\begin{align}
  \E \left [ \left ( \frac{q'}{dd'} \right )^p \right ]
  &\leq \sqrt{\E |q'|^{2p} \E |dd'|^{-2p}} \nonumber \\
  &\leq \sqrt{\E |q|^{2p} \sqrt{\E |d|^{-4p} \E |d'|^{-4p}}} \nonumber \\
  &\leq \sqrt{\E |q|^{2p} \sqrt{\E |d|^{-4p} \E |d|^{-4p}}} \nonumber \\
  &\leq \sqrt{\E |q|^{2p} \E |d|^{-4p}} \nonumber \\ 
  &\leq \sqrt{f_{c_5}(2p) N^{2p/2} f_{c_2}(4p) N^{-4p/2}} \text{ from
  } (\ref{def:qp}) \text{ and } (\ref{def:dp}) \nonumber \\
  &\leq \sqrt{f_{c_5}(2p) f_{c_2}(4p)} N^{-p/2} \nonumber \\
  &:= f_{c_6}(p) N^{-p/2} \label{def:qpddp}.
\end{align}

\section{Proof}
$T$ and $T'$ are exchangeable by construction.  $T$ (and thus $T'$ by
exchangeability) has mean zero by symmetry ($P(T = t) = P(T = -t)$ by
switching groups).

\begin{proposition}
  $|\var(T)-1| \leq cN^{-1}$ for some $c>0$.
\end{proposition}
\begin{proof}
  \begin{align}
    \var(T) &= \E[T^2] \nonumber \\
    &= \E \left [\frac{N-1}{N} \frac{
        (\sum_{i=1}^N u_i - \sum_{i=N+1}^{2N}u_i)^2}
      {\sum_{i=1}^{2N}u_i^2-N\bar{u}_1^2-N\bar{u}_2^2} \right ] \nonumber \\
    &= \frac{N-1}{N} \E \left [\frac{
        (N\bar{u}_1-N\bar{u}_2)^2}
      {\sum_{i=1}^{2N}u_i^2-N\bar{u}_1^2-N\bar{u}_2^2} \right ] \nonumber \\
    &= (N-1)\E \left [\frac{
        4 N\bar{u}_2^2}{2N-2N\bar{u}_2^2} \right ] \nonumber \\
    &= 2(N-1)\E \left [\frac{
        \bar{u}_2^2}{1-\bar{u}_2^2} \right ] \nonumber \\
    &= 2(N-1) \E[g(\bar{u}_2)], \label{def:varT}
  \end{align}
  where $g(x) = \frac{x^2}{1-x^2}$. 

  Mean-centering the $u_i$ has the effect of mean-centering $\bar{u}_2$:
  \begin{equation*}
    \E[\bar{u}_2] = 
    \frac{1}{N} \E \left [ \sum_{i=N+1}^{2N} u_i \right ] = 
    \frac{1}{N} \sum_{i=N+1}^{2N} \E[u_i] = 
    \frac{1}{N} \sum_{i=N+1}^{2N} \frac{1}{2N} \sum_{i=1}^N u_i = 0
  \end{equation*}
  Under independence, $\var(\bar{u}_2)$ would be $\frac{1}{N}$ given
  the scaling.  However, the negative dependence induced by the
  permutation structure approximately halves this value.
  The scaling is such that $\var(u_i) = 1$.  Under independence and
  with $i \neq j$, $\var(u_i + u_j) = 2$.  Summing only 2 (out of $2N$)
  values under permutation dependence, $\var(u_i + u_j) = 2 - \frac{2}{2N-1}$.
  \begin{align*}
    \var(\bar{u}_2) 
    &= \frac{1}{N^2} \E \left [\left (\sum_{i=N+1}^{2N}u_i\right
      )^2\right ] \\
    &= \frac{1}{N^2} \E \left [\sum_{i=N+1}^{2N} u_i^2 +
    \sum_{i=N+1}^{2N}\sum_{j=N+1, j\neq i}^{2N}u_iu_j \right ] \\
    &= \frac{1}{N^2} \sum_{i=N+1}^{2N} \frac{1}{2N} \sum_{j=1}^{2N} u_j^2
    + \frac{1}{N^2}\sum_{i=N+1}^{2N}\sum_{j=N+1, j\neq
      i}^{2N} \E[u_i u_j] \\
    &= \frac{1}{N} + \frac{1}{N^2}\sum_{i=N+1}^{2N}\sum_{j=N+1, j\neq
      i}^{2N} \frac{1}{2N}\frac{1}{2N-1}\sum_{k=1}^{2N}
    \sum_{l=1, l\neq k}^{2N} u_ku_l \\
    &= \frac{1}{N} + \frac{1}{N^2}\sum_{i=N+1}^{2N}\sum_{j=N+1, j\neq
      i}^{2N} \frac{1}{2N}\frac{1}{2N-1} \left (
    \left (\sum_{k=1}^{2N} u_k \right )^2 - \sum_{k=1}^{2N} u_k^2
  \right ) \\
    &= \frac{1}{N} + \frac{1}{N^2}\sum_{i=N+1}^{2N}\sum_{j=N+1, j\neq
      i}^{2N} \frac{1}{2N}\frac{1}{2N-1} \left (
    0^2 - 2N \right ) \\
    &= 1 + \frac{1}{N}(N^2-N)\left (-\frac{1}{2N-1}\right ) \\
    &= 1 + (1-N)\left (\frac{1}{2N-1}\right ) \\
    &= 1 - \frac{1}{2} + \frac{2N-1}{4N-2} + \frac{2-2N}{4N-2} \\
    &= \frac{1}{2} + \frac{1}{4N-2} \\
    &= \frac{1}{2N-1}
  \end{align*}

  By Taylor's theorem, we expand the function $g(\bar{u}_2) =
  \frac{\bar{u}_2^2}{1-\bar{u}_2^2}$ around $\E[\bar{u}_2] = 0$: 
  \begin{equation*}
    g(\bar{u}_2) = \frac{\bar{u}_2^2}{1-\bar{u}_2^2} = g(0) + g'(0)
    \bar{u}_2 + \frac{g''(0)}{2!}\bar{u}_2^2 +
    \frac{g^{(3)}(0)}{3!}\bar{u}_2^3 + R_3(\bar{u}_2),
  \end{equation*}
  where $R_3(\bar{u}_2) = \frac{g^{(4)}(\xi_L)}{4!}\bar{u}_2^4$, with
  $\xi_L \in [0, \bar{u}_2]$.

  From (\ref{def:varT}) and evaluating the Taylor series, we have 
  \begin{equation*}
    \frac{\var(T)}{2(N-1)} = \E[\bar{u}_2^2 + R_3(\bar{u}_2)].
  \end{equation*}
  Therefore,
  \begin{align*}
    \left | \frac{\var(T)}{2(N-1)} - \E[\bar{u}_2^2] \right | 
    &= \left | \frac{\var(T)}{2(N-1)} - \frac{1}{2N-1} \right | \\
    &\leq  \E |R_3(\bar{u}_2)| \\
    &\leq \E \left | \frac{24(5\bar{u}_2^4 + 10  \bar{u}_2^2 +
        1)}{4!(\bar{u}_2-1)^5}\bar{u}_2^4  \right |, \quad
    \bar{u}_2 \leq B < 1 \\
    &\leq \frac{5B^4+10B^2+1}{|B-1|^5} \E [\bar{u}_2^4] \\
    &\leq \frac{5B^4+10B^2+1}{|B-1|^5} f_{c_1}(4) N^{-2} \quad \text{
      by } (\ref{def:serfling}) \\
    &:= c_1 N^{-2}
  \end{align*}
  
  \begin{align*}
    |\var(T) - 1| - \frac{1}{2N-1} 
    &\leq \left | \var(T) - 1 + \frac{1}{2N-1} \right | \\
    &= \left | \var(T) - \frac{2(N-1)}{2N-1} \right | \\
    &= 2(N-1) \left | \frac{\var(T)}{2(N-1)} - \frac{1}{2N-1} \right | \\
    &\leq c_1 2(N-1)N^{-2}
  \end{align*}
  
  This implies that 
  \begin{equation*}
    |\var(T) - 1| \leq \frac{1}{2N-1} + c_1 \frac{2N-2}{N^2} \leq
    \frac{1 + 2c_1}{N}
  \end{equation*}
\end{proof}

\begin{proposition}
  $B$ is $O(N^{-1})$.
\end{proposition}
\begin{proof}
  With two applications of the $c_r$ inequality, we can bound the
  variance of the sum by a constant times the sum of the variances.  
  Suppose $X$, $Y$, and $Z$ are centered random variables with finite
  variances.  Then, 
  \begin{align*}
    \var(X+Y+Z) &= \E[|(X+Y)+Z|^2] \\
    &\leq 2 \E[|X+Y|^2] + 2\E[|Z|^2] \\
    &\leq 2(2\E[|X|^2] + 2\E[|Y|^2]) + 2\E[|Z|^2] \\
    &\leq 4(\var(X) + \var(Y) + \var(Z))
  \end{align*}

  \begin{align*}
    \var (\E[(T'-T)^2 | \pi]) &= \var \left ( \frac{N-1}{N}\E \left [
      \left ( \frac{2u_J-2u_I}{d}+T'\frac{d-d'}{d} \right )^2
        \middle | \pi \right ] \right ) \\
    &\leq \var \left ( \E \left [
      \left ( \frac{2u_J-2u_I}{d}+T'\frac{d-d'}{d} \right )^2
        \middle | \pi \right ] \right ) \\
    &\leq 4(\var(X) + \var(Y) + \var(Z))
  \end{align*}
  where
  \begin{align*}
    X &= \E \left [ \left ( \frac{2u_J-2u_I}{d} \right )^2
        \middle | \pi \right ] \\
    Y &= \E \left [ \left
          ( T'\frac{d-d'}{d} \right )^2 \middle | \pi \right ] \\
    Z &= 2 \E \left [ \left ( \frac{2u_J-2u_I}{d}
         T'\frac{d-d'}{d} \right ) \middle | \pi \right ]
  \end{align*}

  The first term is going to dominate.
  \begin{align*}
    \var(X) 
    &= \var \left ( \E \left [ \left ( \frac{2u_J-2u_I}{d} \right )^2
       \middle | \pi \right ] \right ) \\
   &= \var (\E [(2u_J-2u_I)^2 | \pi ] \E[d^{-2} | \pi] ) \\
   &= \var (d^{-2} \E [(2u_J-2u_I)^2 | \pi ]) \\
   &\leq (f_{c_2}(2) N^{-2/2})^2 \var(\E [(2u_J-2u_I)^2 | \pi ]) 
   \text{ from } (\ref{def:dp}) \\
   &= (f_{c_2}(2))^2 N^{-2} \var(\E [(2u_J-2u_I)^2 | \pi ]),
  \end{align*}
  where
  \begin{align*}
    \var (\E[(2u_J-2u_I)^2 | \pi]) 
    &= \var(\E[u_J^2+u_I^2-2u_Ju_I|\pi]) \\
    &= \var \left ( \frac{1}{N^2} \sum_{I=1}^{N}\sum_{J=N+1}^{2N}
    (u_J^2+u_I^2-2u_Ju_I) \right ) \\
    &= \var \left ( \frac{1}{N^2} \left ( N \sum_{K=1}^{2N}u_K^2 -
      \sum_{I=1}^{N}\sum_{J=N+1}^{2N}2u_Ju_I \right ) \right ) \\
    &= \frac{4}{N^4}
    \sum_{I=1}^{N}\sum_{J=N+1}^{2N}\sum_{K=1}^{N}\sum_{L=N+1}^{2N}
    \cov(u_{\pi(I)}u_{\pi(J)},u_{\pi(K)}u_{\pi(L)})
  \end{align*}
  since $\sum_{K=1}^{2N}u_K^2 = 2N$ is a constant.

  In order to calculate the covariance terms, we need to consider each
  case separately.
  Case $I \neq J \neq K \neq L$: 
  \begin{equation*}
    \E[u_{\pi(I)}u_{\pi(J)},u_{\pi(K)}u_{\pi(L)}] =
    \frac{1}{2N}\frac{1}{2N-1}\frac{1}{2N-2}\frac{1}{2N-3} \left ( -6
      \sum_{i=1}^{2N}u_i^4 + 12N^2 \right ) 
  \end{equation*}
  and
  \begin{equation*}
    \E[u_{\pi(I)}u_{\pi(J)}] = \E[u_{\pi(K)}u_{\pi(L)}] =
    -\frac{1}{2N-1},
  \end{equation*}
  with $N^2(N-1)^2$ choices.
  
  Case $I=K, J=L$:
  \begin{equation*}
    \E[u_{\pi(I)}^2 u_{\pi(J)}^2] = \frac{2N}{2N-1} -
    \frac{1}{2N}\frac{1}{2N-1}\sum_{i=1}^{2N}u_i^4 
  \end{equation*}
  with $N^2$ choices.

  Case $I=K, J\neq L$ or $I\neq K, J= L$:
  \begin{equation*}
    \E[u_{\pi(I)}^2 u_{\pi(J)}u_{\pi(L)}] =
    \frac{1}{2N}\frac{1}{2N-1}\frac{1}{2N-2}\left (
      2 \sum_{i=1}^{2N} u_i^4 - 4N^2 \right ) 
  \end{equation*}
  with $2N^2(N-1)$ choices.  

  Putting it all together, we have 
  \begin{align*}
    \var (\E[(2u_J-2u_I)^2]) &= 4 \frac{N^2(N-1)^2}{N^4(2N)(2N-1)(2N-2)(2N-3)} \left ( -6
      \sum_{i=1}^{2N}u_i^4 + 12N^2 - \frac{1}{(2N-1)^2} \right ) \\
    &+ 4 \frac{N^2}{N^4} \left ( \frac{2N}{2N-1} -
    \frac{1}{2N}\frac{1}{2N-1}\sum_{i=1}^{2N}u_i^4 - \frac{1}{(2N-1)^2}
  \right ) \\
  &+ 4 \frac{2N^2(N-1)}{N^4} \left ( 
    \frac{1}{2N}\frac{1}{2N-1}\frac{1}{2N-2}\left (
      2 \sum_{i=1}^{2N} u_i^4 - 4N^2 \right ) - \frac{1}{(2N-1)^2}
  \right ) \\
  &\leq \frac{48}{4N^2} + \frac{8}{N^2} + \frac{16 \sum_{i=1}^{2N}
    u_i^4}{N^4} \\
  &= \frac{20}{N^2} + 16\frac{\sum_{i=1}^{2N} u_i^4}{N^4}.
  \end{align*}
  
  Therefore, 
  \begin{equation*}
    \var(X) = (f_{c_2}(2))^2 N^{-2} \var(\E [(2u_J-2u_I)^2 | \pi ])
    \leq (f_{c_2}(2))^2 N^{-4} \left (20 + 16\frac{\sum_{i=1}^{2N}
        u_i^4}{N^2} \right ).
  \end{equation*}
  
  Because the latter two terms are much smaller in order, we can apply
  coarser techniques.  In particular, we use the following bound:
  \begin{equation*}
    \var (\E[U|V]) = \var(U) - \E (\var (U|V)) \leq E[U^2]
  \end{equation*}

  Applying to the second term,
  \begin{align*}
    \var(Y) &= \var \left ( \E \left [ \left ( T'\frac{d-d'}{d} \right )^2
        \middle | \pi \right ] \right ) \\
    &\leq \E \left [ \left ( \frac{q'}{dd'} (d-d') \right )^4 \right ] \\
    &\leq \sqrt{\E \left [ \left ( \frac{q'}{dd'} \right )^8 \right ]
      \E [(d-d')^8]} \\
    &\leq \sqrt{f_{c_6}(8) N^{-8/2} f_{c_4}(8) N^{-8}} \text{ from }
    (\ref{def:qpddp}),(\ref{def:ddiffp}) \\
    &= \sqrt{f_{c_6}(8)f_{c_4}(8)}N^{-6}.
  \end{align*}

  And to the third,
  \begin{align*}
    \var(Z) &= 4 \var \left ( \E \left [ \left ( \frac{2u_J-2u_I}{d}
          T'\frac{d-d'}{d} \right ) \middle | \pi \right ] \right ) \\
    &\leq 4 \E \left [ \left ( \frac{1}{d} \frac{q'}{dd'}
        (2u_J-2u_I)(d-d') \right )^2 \right ] \\
    &\leq 4 f_{c_2}(2) N^{-2/2} \sqrt{\E \left [ \left (
          \frac{q'}{dd'} \right )^4 \right ] \E[((2u_J-2u_I)(d-d'))^4]
    } \text{ from } (\ref{def:dp}) \\
    &\leq 4 f_{c_2}(2) N^{-1} \sqrt{\E \left [ \left (
          \frac{q'}{dd'} \right )^4 \right ] \sqrt{\E[(2u_J-2u_I)^8]
      \E[(d-d')^8]}} \\
    &\leq 4 f_{c_2}(2) N^{-1} \sqrt{f_{c_6}(4) N^{-4/2} \sqrt{2^9
        \frac{\sum_{i=1}^{2N}u_i^4}{2N} f_{c_4}(8) N^{-8}}}
    \text{ from } (\ref{def:qpddp}),(\ref{def:ddiffp}) \\
    &\leq 2^{4.25}f_{c_2}(2) (f_{c_6}(4))^{-1/2} (f_{c_4}(8))^{-1/4}
    (\sum_{i=1}^{2N}u_i^4)^{1/4} N^{-4.25}
  \end{align*}
\end{proof}

\begin{proposition}
  $(2\pi)^{-1/4}\sqrt{\frac{\E|T'-T|^3}{\lambda}}$ is
  $O(N^{-1/4})$.
\end{proposition}
\begin{proof}
  The strategy is to break apart the remainder term from the main piece.  

  From (\ref{def:ttpcubed}),
  \begin{align*}
    \E|T'-T|^3 
    &= \left (\frac{N-1}{N}\right )^{3/2}
    \E \left [d^{-3} \left |2u_J-2u_I+q'\frac{d-d'}{d'} \right |^3
    \right ] \\
    &\leq 8 \left (
      \E \left [ \frac{|2u_J-2u_I|^3}{d^3} \right ] + 
      \E \left [ \left | q'\frac{d-d'}{dd'} \right |^3
      \right ] \right ) \\
    &\leq 8 \left (
      \E \left [ |2u_J-2u_I|^3 \right ] \E [d^{-3}] + 
      \sqrt{\E \left [ \left ( \frac{q'}{dd'} \right )^6 \right ]  \E
        [(d-d')^6]} \right ) \\
    &\leq 8 \left ( 128 \frac{\sum_{i=1}^{2N} |u_i|^3}{2N} \right )
    f_{c_2}(3) N^{-3/2} + 
    8 \sqrt{f_{c_6}(6) N^{-6/2} f_{c_4}(6) N^{-6}} \text{ from } 
    (\ref{def:dp}),(\ref{def:qpddp}),(\ref{def:ddiffp}) \\
    &\leq 1024 f_{c_2}(3) \left ( \frac{\sum_{i=1}^{2N} |u_i|^3}{2N}
    \right ) N^{-3/2} + 8 \sqrt{f_{c_6}(6)f_{c_4}(6)} N^{-3} N^{-3/2} \\
    &\leq \left ( 1024 f_{c_2}(3) \left ( \frac{\sum_{i=1}^{2N} |u_i|^3}{2N}
    \right ) + 8 \sqrt{f_{c_6}(6)f_{c_4}(6)} \right ) N^{-3/2}
  \end{align*}

  Thus, $(2\pi)^{-1/4}\sqrt{\frac{\E|T'-T|^3}{\lambda}}$ is $O(N^{-1/4})$.
\end{proof}

\begin{proposition}
  $\E|R|$ is $O(N^{-1/2})$.
\end{proposition}
\begin{proof}
  \begin{align*}
    \E|R| &= \E \left | \left (\frac{N}{2}\right )
      \sqrt{\frac{N-1}{N}}\frac{1}{d}\E
      \left [q'\frac{(d-d')}{d'} \middle | T \right ]\right | \\
    &\leq \frac{N}{2} \E \left | \frac{q'}{dd'}(d-d') \right | \\
    &\leq \frac{N}{2} \sqrt{\E \left | \frac{q'}{dd'} \right |^2
      \E[d-d']^2} \\
    &\leq \frac{N}{2} \sqrt{f_{c_6}(2) N^{-2/2} f_{c_4}(2) N^{-2}}
    \text{ from } (\ref{def:qpddp}), (\ref{def:ddiffp}) \\
    &=\frac{1}{2}\sqrt{f_{c_6}(2)f_{c_4}(2)} N^{-1/2}
  \end{align*}
\end{proof}

